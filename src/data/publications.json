{
    "publications": [
        {
            "title": "The Geometry of Alignment Collapse: When Fine-Tuning Breaks Safety",
            "main_authors": [
                "Max Springer"
            ],
            "contributors": [
                "Chung Peng Lee",
                "Blossom Metevier",
                "Jane Castleman",
                "Bohdan Turbal",
                "Hayoung Jung",
                "Zeyu Shen",
                "Aleksandra Korolova"
            ],
            "venue": "Preprint",
            "paper_url": "https://arxiv.org/abs/2602.15799",
            "code_url": ""
        },
        {
            "title": "WorldBench: A Challenging and Visually Diverse Multimodal Benchmark",
            "main_authors": [
                "Yida Yin"
            ],
            "contributors": [
                "Harish Krishnakumar",
                "Chung Peng Lee",
                "Boya Zeng",
                "Wenhao Chai",
                "Shengbang Tong",
                "Wenhu Chen",
                "Hu Xu",
                "Xingyu Fu",
                "Gabriel Herbert Sarch",
                "Aleksandra Korolova",
                "Zhuang Liu"
            ],
            "venue": "CVPR 2026",
            "paper_url": "",
            "code_url": ""
        },
        {
            "title": "How do data owners say no? A case study of data consent mechanisms in web-scraped vision-language AI training datasets",
            "main_authors": [
                "Chung Peng Lee"
            ],
            "contributors": [
                "Rachel Hong",
                "Harry H. Jiang",
                "Aster Plotnik",
                "William Agnew",
                "Jamie Morgenstern"
            ],
            "venue": "Oral in AAAI (AI for Societal Impact Track) 2026, Oral in NeurIPS RegML Workshop 2025",
            "paper_url": "https://arxiv.org/abs/2511.08637",
            "code_url": "https://github.com/Anderson-Lee-Git/tracing-data-consent-in-datacomp/tree/main"
        },
        {
            "title": "Escaping the SpuriVerse: Can Large Vision-Language Models Generalize Beyond Seen Spurious Correlations?",
            "main_authors": [
                "Yiwei Yang",
                "Chung Peng Lee"
            ],
            "contributors": [
                "Shangbin Feng",
                "Dora Zhao",
                "Bingbing Wen",
                "Anthony Liu",
                "Yulia Tsvetkov",
                "Bill Howe"
            ],
            "venue": "NeurIPS Datasets and Benchmarks 2025",
            "paper_url": "https://arxiv.org/abs/2506.18322",
            "code_url": "https://github.com/Anderson-Lee-Git/SpuriVerse"
        },
        {
            "title": "Fairness through partial awareness: Evaluation of the addition of demographic information for bias mitigation methods",
            "main_authors": [
                "Chung Peng Lee"
            ],
            "contributors": [
                "Rachel Hong",
                "Jamie Morgenstern"
            ],
            "venue": "ICML Next Generation of AI Safety Workshop 2024",
            "paper_url": "https://openreview.net/forum?id=e4GjJrfrlb",
            "code_url": ""
        }
    ]
}